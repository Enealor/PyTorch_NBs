{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Stage VAE\n",
    "\n",
    "An article from NeurIPS 2018 recently explained a way of altering Variational Autoencoders that leads to better image results. This is measured against the tensorflow implementation of FID, which is used to determine image diversity (i.e. how many different images the generator can produce) and image quality (i.e. how similar the generated images are to real images, as measured by a particular network). \n",
    "\n",
    "In brief, the alteration is to change how we measure the reconstruction. A typical measure of the reconstruction is the log probability of the outcome. Given an observation $x$, \n",
    "\n",
    "\n",
    "This shortcoming is that the network is more apt to learn the *shape* of the manifold rather than the *distribution of data* on the manifold. Because of this, a standard VAE finds itself producing blurry pictures due to this mismatch in distribution. To remedy this, they propose a simple fix: add a second VAE to learn the distribution of data, once the shape of the manifold has been reasonably learned.\n",
    "\n",
    "This notebook is an implementation of this idea in pytorch. The network used herein is much smaller, but the result should still be observable with a small network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pylab as plt\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "from math import sqrt, exp\n",
    "from numpy import linspace\n",
    "from time import time\n",
    "\n",
    "from torchvision.transforms.functional import to_pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 125\n",
    "\n",
    "#Choose data set and batch size\n",
    "means = [0.49139967861519745, 0.4821584083946076, 0.44653091444546616]\n",
    "stdevs = [0.2470322324632823, 0.24348512800005553, 0.2615878417279641]\n",
    "transforms = Compose([ToTensor(), Normalize(means, stdevs)])\n",
    "training_set = datasets.CIFAR10(root='./data/', train=True, download=False, transform=transforms)\n",
    "testing_set = datasets.CIFAR10(root='./data/', train=False, download=False, transform=transforms)\n",
    "\n",
    "training_loader = t.utils.data.DataLoader(dataset=training_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "testing_loader = t.utils.data.DataLoader(dataset=testing_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "#Set image size. This is done for convenience when changing data.\n",
    "image_shape = (3, 32, 32)\n",
    "image_size = image_shape[0]*image_shape[1]*image_shape[2]\n",
    "out_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShiftDropout(nn.Module):\n",
    "    def __init__(self, keep_prob=.1, training=True):\n",
    "        assert keep_prob > 0. and keep_prob < 1.\n",
    "        super(ShiftDropout, self).__init__()\n",
    "        self.training = training\n",
    "        self.keep_prob = keep_prob\n",
    "        alpha01, lambda01 = 2.90427, 1.07862\n",
    "        self.min = -alpha01*lambda01*exp(-1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        #If we are not training, we leave the input as is.\n",
    "        if not self.training:\n",
    "            return input\n",
    "        else:\n",
    "            mask = t.rand_like(input) < self.keep_prob\n",
    "            x = mask*input+(~mask)*self.min\n",
    "            return (mask*input-(1-self.keep_prob)*self.min)/self.keep_prob\n",
    "\n",
    "def SERLU(input):\n",
    "    alpha01, lambda01 = 2.90427, 1.07862\n",
    "    return lambda01*(input*(input>=0)+alpha01*input*t.exp(input)*(input<0))\n",
    "\n",
    "def init_SNN_weights(module):\n",
    "    if type(module) is nn.Linear:\n",
    "        std = 1./sqrt(module.weight.numel())\n",
    "        nn.init.normal_(module.weight, 0, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress(intro_dict, progress_dict):\n",
    "    '''\n",
    "    Prints information from two dictionaries. The first dictionary is printed verbatim,\n",
    "    while the second dictionary is rounded to 4 decimals. The values of the second\n",
    "    dictionary must be floats.\n",
    "    \n",
    "    :param intro_dict: (dict) Information about the current time. The {key: value}\n",
    "        pair can have any value that can be used in a str format.\n",
    "    :param progress_dict: (dict) Information about current progress. The {key: value}\n",
    "        pair must have a float for the value.\n",
    "    '''\n",
    "    intro_text = '{}: {:4}'\n",
    "    intros = [intro_text.format(key, value) for key, value in intro_dict.items()]\n",
    "    update_text = '{}: {:.4f}'\n",
    "    updates = [update_text.format(key, value) for key, value in progress_dict.items()]\n",
    "    print(*intros, *updates, sep=' - ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBatchNorm(nn.Module):\n",
    "    def __init__(self, BatchNorm, n_copies=1):\n",
    "        super(MultiBatchNorm, self).__init__()\n",
    "        self.main_bn = BatchNorm\n",
    "        assert type(BatchNorm) in [nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d],\n",
    "            'Requires BatchNorm to be a torch.nn.BatchNorm object instead of {}'.format(type(BatchNorm))\n",
    "        #Get proper layer\n",
    "        if type(BatchNorm) is nn.BatchNorm1d:\n",
    "            module = nn.BatchNorm1d\n",
    "        elif type(BatchNorm) is nn.BatchNorm2d:\n",
    "            module = nn.BatchNorm2d\n",
    "        elif type(BatchNorm) is nn.BatchNorm3d:\n",
    "            module = nn.BatchNorm3d\n",
    "            \n",
    "        #Collect parameters\n",
    "        params = [\n",
    "            BatchNorm.num_features,\n",
    "            BatchNorm.eps,\n",
    "            BatchNorm.momentum,\n",
    "            BatchNorm.affine,\n",
    "            BatchNorm.track_running_stats\n",
    "        ]\n",
    "        self.aux_bn = [module(*params) for _ in n_copies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU_Block(nn.Module):\n",
    "    '''\n",
    "    Creates a RELU block.\n",
    "    '''\n",
    "    def __init__(self, in_features, out_features, dropout=True, dropout_prob=.1, batch_norm=True, bias=True):\n",
    "        super(ReLU_Block, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features, bias)\n",
    "        \n",
    "        if batch_norm:\n",
    "            self.batch_norm = nn.BatchNorm1d(out_features)\n",
    "        else:\n",
    "            self.register_parameter('batch_norm', None)\n",
    "            \n",
    "        if dropout:\n",
    "            self.dropout = nn.Dropout(dropout_prob)\n",
    "        else:\n",
    "            self.register_parameter('dropout', None)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        if self.dropout is not None:\n",
    "            input = self.dropout(input)\n",
    "        x = self.linear(input)\n",
    "        if self.batch_norm is not None:\n",
    "            x = self.batch_norm(x)\n",
    "\n",
    "        return nn.functional.relu(x)\n",
    "    \n",
    "class SELU_Block(nn.Module):\n",
    "    '''\n",
    "    Creates a SELU block.\n",
    "    '''\n",
    "    def __init__(self, in_features, out_features, dropout=True, dropout_prob=.1, bias=True):\n",
    "        super(SELU_Block, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features, bias)\n",
    "        init_SNN_weights(self.linear)\n",
    "        \n",
    "        if dropout:\n",
    "            self.dropout = nn.AlphaDropout(dropout_prob)\n",
    "        else:\n",
    "            self.register_parameter('dropout', None)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        if self.dropout is not None:\n",
    "            input = self.dropout(input)\n",
    "        return nn.functional.selu(self.linear(input))\n",
    "    \n",
    "class SERLU_Block(nn.Module):\n",
    "    '''\n",
    "    Creates a SERLU block.\n",
    "    '''\n",
    "    def __init__(self, in_features, out_features, dropout=True, dropout_prob=.1, bias=True):\n",
    "        super(SERLU_Block, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features, bias)\n",
    "        init_SNN_weights(self.linear)\n",
    "        \n",
    "        if dropout:\n",
    "            self.dropout = ShiftDropout(dropout_prob)\n",
    "        else:\n",
    "            self.register_parameter('dropout', None)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        if self.dropout is not None:\n",
    "            input = self.dropout(input)\n",
    "        return SERLU(self.linear(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier(nn.Module):\n",
    "    def __init__(self, image_size, classes, depth, block_type, block_kws={}, name='default'):\n",
    "        super(classifier, self).__init__()\n",
    "        self.classes = classes\n",
    "        if block_type == 'serlu':\n",
    "            block = SERLU_Block\n",
    "        elif block_type == 'selu':\n",
    "            block = SELU_Block\n",
    "        else:\n",
    "            block = ReLU_Block\n",
    "            \n",
    "        layer_sizes = linspace(image_size, classes, depth, dtype=int)\n",
    "        in_sizes, out_sizes = layer_sizes[:-1], layer_sizes[1:]\n",
    "        \n",
    "        net = [nn.Flatten()]\n",
    "        assert depth >= 1, 'Depth must be at least 1. Recieved {0}'.format(depth)\n",
    "        for in_size, out_size in zip(in_sizes[:-1], out_sizes[:-1]):\n",
    "            net.append(block(in_size, out_size, **block_kws))\n",
    "            \n",
    "        if 'bias' in block_kws:\n",
    "            bias = block_kws['bias']\n",
    "        else:\n",
    "            bias = True\n",
    "        net.append(nn.Linear(in_sizes[-1], out_sizes[-1], bias))\n",
    "        self.net = nn.Sequential(*net)\n",
    "        \n",
    "        self.name = name\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.net(input)\n",
    "    \n",
    "    def classify(self, input):\n",
    "        _, classes = t.max(self.net(input), 1)\n",
    "        return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(classifier, optimizer, epochs, device, verbose=True):\n",
    "    history = []\n",
    "    cum_time = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        classifier.train()\n",
    "        for batch_nb, batch in enumerate(training_loader):\n",
    "            images, labels = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "            start = time()\n",
    "            #Assign nats\n",
    "            x = classifier(images)\n",
    "\n",
    "            #Compute loss\n",
    "            loss = nn.functional.cross_entropy(x, labels)\n",
    "            \n",
    "            #Update network\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            cum_time += time()-start\n",
    "\n",
    "        #Validate after training\n",
    "        score = test_classifier(classifier, device)\n",
    "        if verbose:\n",
    "            print_progress({'epoch': epoch}, {'Portion correct': score})\n",
    "        history.append(score)\n",
    "    return history, cum_time\n",
    "\n",
    "def test_classifier(classifier, device):\n",
    "    correct = 0\n",
    "    nb_samples = len(testing_set)\n",
    "    with t.no_grad():\n",
    "        classifier.eval()\n",
    "        for batch in testing_loader:\n",
    "            images, labels = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "            #Assign classes\n",
    "            assigned = classifier.classify(images)\n",
    "\n",
    "            #Compute correct assigned\n",
    "            correct += float(t.sum(assigned==labels))\n",
    "\n",
    "    return correct/nb_samples\n",
    "\n",
    "def attack_classifier(classifier, device):\n",
    "    correct = 0\n",
    "    nb_samples = len(testing_set)\n",
    "    with t.no_grad():\n",
    "        classifier.eval()\n",
    "        for batch in testing_loader:\n",
    "            images, labels = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "            #Assign classes\n",
    "            assigned = classifier.classify(images)\n",
    "\n",
    "            #Compute correct assigned\n",
    "            correct += float(t.sum(assigned==labels))\n",
    "\n",
    "    return correct/nb_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose training device (cpu vs gpu/cuda) based on availability\n",
    "device = 'cuda' if t.cuda.is_available() else 'cpu'\n",
    "\n",
    "out_size = 10\n",
    "epochs = 15\n",
    "depths = [4, 8, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train relu-4: 0 m 58.8 s.\n",
      "Final validation accuracy: 57.6%\n",
      "Time to train relu-8: 2 m 19.2 s.\n",
      "Final validation accuracy: 57.8%\n",
      "Time to train relu-12: 3 m 38.3 s.\n",
      "Final validation accuracy: 57.4%\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "relu_history = []\n",
    "for depth in depths:\n",
    "    name = 'relu-{0}'.format(depth)\n",
    "    ReLU_net = classifier(image_size, out_size, depth, 'relu', name=name)\n",
    "    ReLU_optim = t.optim.Adam(ReLU_net.parameters(), lr=lr)\n",
    "    ReLU_net.to(device)\n",
    "    history, cum_time = train_classifier(ReLU_net, ReLU_optim, epochs, device, verbose=False)\n",
    "    relu_history.append(history)\n",
    "    print('Time to train {0}: {1:.0f} m {2:.1f} s.'.format(name, cum_time//60, cum_time%60))\n",
    "    print('Final validation accuracy: {0:.1%}'.format(history[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train selu-4: 0 m 31.1 s.\n",
      "Time to train selu-8: 1 m 10.1 s.\n",
      "Time to train selu-12: 1 m 54.7 s.\n"
     ]
    }
   ],
   "source": [
    "selu_history = []\n",
    "\n",
    "for depth in depths:\n",
    "    name = 'selu-{0}'.format(depth)\n",
    "    SELU_net = classifier(image_size, out_size, depth, 'selu', {'bias': False}, name=name)\n",
    "    SELU_optim = t.optim.Adadelta(SELU_net.parameters())\n",
    "    SELU_net.to(device)\n",
    "    history, cum_time = train_classifier(SELU_net, SELU_optim, epochs, device, verbose=False)\n",
    "    selu_history.append(history)\n",
    "    print('Time to train {0}: {1:.0f} m {2:.1f} s.'.format(name, cum_time//60, cum_time%60))\n",
    "    print('Final validation accuracy: {0:.1%}'.format(history[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SERLU_net = classifier(image_size, out_size, depth, h_size, 'serlu')\n",
    "# #Move networks to selected device\n",
    "# SERLU_net.to(device)\n",
    "\n",
    "# #Set up optimizer\n",
    "# SERLU_optim = t.optim.Adamax(SERLU_net.parameters(), lr=0.0005)\n",
    "\n",
    "# #Train\n",
    "# train_classifier(SERLU_net, SERLU_optim, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adversary(classifier, image, desired_label, iterations, scale=1., lr=5e-2):\n",
    "    classifier.eval()\n",
    "    noise = t.zeros_like(image, requires_grad=True)\n",
    "    optim = t.optim.SGD([noise], lr=lr)\n",
    "    for _ in range(iterations):\n",
    "        optim.zero_grad()\n",
    "        new_image = (image+noise)/t.max(image+noise)\n",
    "        loss = nn.functional.cross_entropy(classifier(new_image), desired_label)+scale*noise.norm()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGSA(image, grad_data, eps):\n",
    "    noise = grad_data.sign()\n",
    "    new_image = t.clamp(image+eps*noise, 0, 1)\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.to(device)\n",
    "image.requires_grad = True\n",
    "predictions = SELU_net(image)\n",
    "loss = nn.functional.cross_entropy(predictions, t.tensor(label).view(1).to(device))\n",
    "ReLU_net.zero_grad()\n",
    "loss.backward()\n",
    "new_image = FGSA(image, image.grad.data, .05)\n",
    "print(nn.functional.softmax(ReLU_net(new_image), dim=1).tolist())\n",
    "print(label)\n",
    "plt.imshow(to_pil_image(new_image.squeeze().cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def before_and_after(classifier, old_image, old_label, new_image, new_label, class_names):\n",
    "    old_p = nn.functional.softmax(ReLU_net(image), 1).flatten().tolist()\n",
    "    new_p = nn.functional.softmax(ReLU_net(new_image), 1).flatten().tolist()\n",
    "    def _generate_text(label, p):\n",
    "        return '{0}: {1:.6f}'.format(class_names[label], p[label])\n",
    "    old_label = int(old_label)\n",
    "    new_label = int(new_label)\n",
    "    text = ['Before']\n",
    "    text += [_generate_text(old_label, old_p)]\n",
    "    text += [_generate_text(new_label, old_p)]\n",
    "    text += ['After']\n",
    "    text += [_generate_text(old_label, new_p)]\n",
    "    text += [_generate_text(new_label, new_p)]\n",
    "    print(*text, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = training_set[1]\n",
    "plt.imshow(to_pil_image(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.to(device)\n",
    "image = image.reshape((1, *image_shape))\n",
    "new_label = t.tensor(1, device=device).view(1)\n",
    "new_image = create_adversary(ReLU_net, image, new_label, 100, scale=1)\n",
    "\n",
    "p_old = nn.functional.softmax(ReLU_net(image), 1).flatten().tolist()\n",
    "p_new = nn.functional.softmax(ReLU_net(new_image), 1).flatten().tolist()\n",
    "before_and_after(ReLU_net, image, label, new_image, new_label, training_set.classes)\n",
    "\n",
    "new_image = new_image.squeeze()\n",
    "plt.imshow(to_pil_image(new_image.cpu()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_images = training_set.data/255.\n",
    "channel_1 = raw_images[:, :, :, 0]\n",
    "channel_2 = raw_images[:, :, :, 1]\n",
    "channel_3 = raw_images[:, :, :, 2]\n",
    "\n",
    "print([channel_1.mean(), channel_2.mean(), channel_3.mean()])\n",
    "print([channel_1.std(), channel_2.std(), channel_3.std()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = nn.BatchNorm1d(30)\n",
    "st = te.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te.track_running_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
