{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks\n",
    "\n",
    "This is an implementation of a [Generative Adversarial Network (GAN)](https://arxiv.org/abs/1406.2661). The networks used here are based on the [Deep Convolutional GAN](https://arxiv.org/abs/1511.06434) architecture.\n",
    "\n",
    "We apply GANs here to image generation. In order to train a GAN for this, we need a starting set of images which we will call the 'original images.' This is to distinguish it from the 'generated images.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Network\n",
    "### Basic Idea\n",
    "Roughly speaking, the goal of a GAN is to generate images similar to the original images. To do this, a GAN uses two competing networks: a generator and a discriminator. The generator is trained to produce images that resemble our original images. The discriminator is trained to tell the generated images apart from the original images. The process of training the two networks is typically done in the following process:\n",
    "1. We pass generated images along with original images to the discriminator.\n",
    "1. The discriminator assigns a probability that the image is generated or real. If the discriminator assigns a score of $0$, then the image is considered generated. If the discriminator assigns a score of $1$, then the image is considered original. Scores that are between these two reflect uncertainty about the source.\n",
    "1. We score the *discriminator* based on how accurate the probabilities assigned were. We update the discriminator to improve it's ability to assign the correct probability.\n",
    "\n",
    "We then train the generator on a competing goal:\n",
    "1. We pass generated images to the discriminator.\n",
    "1. The discriminator assigns a probability that the image is generated or real.\n",
    "1. We score the *generator* based on how convincing the generated images were. We update the generator so that generated images are more likely to be labeled as original by the discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Function\n",
    "Mathematically, if $D$ is the discriminator and $G$ is the generator, then we can characterize this as a two-player minimax game (i.e. a game where we are trying to minimize the maximum expected loss) with the expected value function\n",
    "\n",
    "$$\\mathbb{E}_{x\\sim p_{\\text{data}}}[\\log D(x)]+\\mathbb{E}_{z\\sim p_{d}}[\\log (1 - D(G(z)))].$$\n",
    "In this equation, the first term scores the original images, while the second term scores the generated images. (Quick math breakdown: $\\mathbb{E}$ means 'expected value,' or what we expect to get based on the distributions. $x\\sim p_{\\text{data}}$ is shorthand for 'x drawn from the distribution of data,' which can be thought of 'x is an original image.' Similarly, $z\\sim p_{d}$ is shorthand for 'z drawn from random noise,' with $G(z)$ being a generated image from random noise.)\n",
    "\n",
    "When we update the discriminator, we update with the intent of increasing the value function. This is accomplished by updating $D$ so that $D(x)$ is closer to $1$ (which increases the first term), and $D(G(z))$ is closer to $0$ (which increases the second term). That is, improving the score of the discriminator on this value function improves the ability of the discriminator to tell apart generated and original images.\n",
    "\n",
    "In contrast, we update $G$ with the intent of lowering the value function. This is why these are adversarial networks: they have competing goals. As the first term does not depend on $G$, the updates only effect the second term. In this situation, $G$ is updated so that $D(G(z))$ is pushed closer to $1$.\n",
    "\n",
    "It's worth noting that there is a critical issue with this function. In particular, if the discriminator is able to tell apart images with a high degree of accuracy early in training, then $\\log(1-D(G(z)))$ will not be able to provide sufficient gradients for training $G$. The reason is due to the saturation, as $\\log(1-D(G(z))$ has vanishing gradients if $D(G(z))$ is very close to 1. Due to this, it is suggested to use a different function for updating the generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternate Generator Score Function\n",
    "To alleviate the problem of vanishing gradients, it is recommended to update $G$ using the value function\n",
    "\n",
    "$$\\mathbb{E}_{z\\sim p_{d}}[\\log D(G(z))].$$\n",
    "\n",
    "By minimizing this score function, we maximize the second term of the original score function. Moreover, the gradients are suitable for learning even when the generator is low quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_factor = 16\n",
    "discriminator = nn.Sequential(\n",
    "    nn.Conv2d(3, channel_factor, 4, 2, bias=False),\n",
    "    nn.BatchNorm2d(channel_factor),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Conv2d(channel_factor, 2*channel_factor, 4, 2, bias=False),\n",
    "    nn.BatchNorm2d(2*channel_factor),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Conv2d(2*channel_factor, 4*channel_factor, 4, 2, bias=False),\n",
    "    nn.BatchNorm2d(4*channel_factor),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Conv2d(4*channel_factor, 1, 4, 2, bias=False),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "generator = nn.Sequential(\n",
    "    nn.ConvTranspose2d(z_size, 4*channel_factor, 4, 2, bias=False),\n",
    "    nn.BatchNorm2d(4*channel_factor),\n",
    "    nn.ReLU(),\n",
    "    nn.ConvTranpose2d(4*channel_factor, 2*channel_factor, 4, 2, bias=False),\n",
    "    nn.BatchNorm2d(2*channel_factor),\n",
    "    nn.ReLU(),\n",
    "    nn.ConvTranpose2d(2*channel_factor, channel_factor, 4, 2, bias=False),\n",
    "    nn.BatchNorm2d(channel_factor),\n",
    "    nn.ReLU(),\n",
    "    nn.ConvTranpose2d(channel_factor, 3, 4, 2, bias=False),\n",
    "    nn.Tanh()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "transforms = Compose([ToTensor(), Normalize([0.5], [0.5])])\n",
    "training_set = datasets.CIFAR10(root='./data/', train=True, download=True, transform=transforms)\n",
    "batch_size = 100\n",
    "training_loader = data.DataLoader(dataset=training_set, batch_size=batch_size, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
