{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdvProp\n",
    "Leveraging adversarial examples.\n",
    "\n",
    "TODO:\n",
    "* ~~Create auxillery batchnorm layer~~\n",
    "* Create function to convert network. Note: Does this make a shallow copy of weights, or do we need a function to transfer weights?\n",
    "* Create function to update batch index\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pylab as plt\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "from math import sqrt, exp\n",
    "from numpy import linspace\n",
    "from time import time\n",
    "\n",
    "from torchvision.transforms.functional import to_pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 125\n",
    "\n",
    "#Choose data set and batch size\n",
    "means = [0.49139967861519745, 0.4821584083946076, 0.44653091444546616]\n",
    "stdevs = [0.2470322324632823, 0.24348512800005553, 0.2615878417279641]\n",
    "transforms = Compose([ToTensor(), Normalize(means, stdevs)])\n",
    "training_set = datasets.CIFAR10(root='./data/', train=True, download=False, transform=transforms)\n",
    "testing_set = datasets.CIFAR10(root='./data/', train=False, download=False, transform=transforms)\n",
    "\n",
    "training_loader = t.utils.data.DataLoader(dataset=training_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "testing_loader = t.utils.data.DataLoader(dataset=testing_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "#Set image size. This is done for convenience when changing data.\n",
    "image_shape = (3, 32, 32)\n",
    "image_size = image_shape[0]*image_shape[1]*image_shape[2]\n",
    "out_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress(intro_dict, progress_dict):\n",
    "    '''\n",
    "    Prints information from two dictionaries. The first dictionary is printed verbatim,\n",
    "    while the second dictionary is rounded to 4 decimals. The values of the second\n",
    "    dictionary must be floats.\n",
    "    \n",
    "    :param intro_dict: (dict) Information about the current time. The {key: value}\n",
    "        pair can have any value that can be used in a str format.\n",
    "    :param progress_dict: (dict) Information about current progress. The {key: value}\n",
    "        pair must have a float for the value.\n",
    "    '''\n",
    "    intro_text = '{}: {:4}'\n",
    "    intros = [intro_text.format(key, value) for key, value in intro_dict.items()]\n",
    "    update_text = '{}: {:.4f}'\n",
    "    updates = [update_text.format(key, value) for key, value in progress_dict.items()]\n",
    "    print(*intros, *updates, sep=' - ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBatchNorm(nn.Module):\n",
    "    def __init__(self, BatchNorm, n_copies=1):\n",
    "        super(MultiBatchNorm, self).__init__()\n",
    "        assert type(BatchNorm) in [nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d], \\\n",
    "            'Requires BatchNorm to be a torch.nn.BatchNorm object instead of {}'.format(type(BatchNorm))\n",
    "        \n",
    "#         self.main_bn = BatchNorm\n",
    "        self.bn_idx = 0\n",
    "        self.register_parameter('main_bn', BatchNorm)\n",
    "        #Get proper layer\n",
    "        if type(BatchNorm) is nn.BatchNorm1d:\n",
    "            module = nn.BatchNorm1d\n",
    "        elif type(BatchNorm) is nn.BatchNorm2d:\n",
    "            module = nn.BatchNorm2d\n",
    "        elif type(BatchNorm) is nn.BatchNorm3d:\n",
    "            module = nn.BatchNorm3d\n",
    "            \n",
    "        #Collect parameters\n",
    "        params = [\n",
    "            BatchNorm.num_features,\n",
    "            BatchNorm.eps,\n",
    "            BatchNorm.momentum,\n",
    "            BatchNorm.affine,\n",
    "            BatchNorm.track_running_stats\n",
    "        ]\n",
    "        #Create auxillery batch norm layers\n",
    "        for _ in range(n_copies):\n",
    "            self.register_parameter('aux_bn', )\n",
    "        self.aux_bn = nn.ModuleList([module(*params) for _ in range(n_copies)])\n",
    "        #Store number of auxillery batch norms\n",
    "        self.n_aux_bn = n_copies\n",
    "        \n",
    "    def forward(self, input):\n",
    "        assert 0 <= self.bn_idx <= self.n_aux_bn, \\\n",
    "            'Batch norm index {0} is out of out of range. Must be between 0 and {1}'.format(bn_idx, self.n_aux_bn)\n",
    "        #Select which batch norm to use.\n",
    "        if self.bn_idx == 0: \n",
    "            # 0 selects main batch norm.\n",
    "            return self.main_bn(input)\n",
    "        else:\n",
    "            # 1 to n_copies selects auxillery batch norms.\n",
    "            return self.aux_bn[self.bn_idx-1](input)\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        self.main_bn.zero_grad()\n",
    "        for aux_bn in self.aux_bn:\n",
    "            aux_bn.zero_grad()\n",
    "        \n",
    "def switch_bn(idx=0):\n",
    "    '''\n",
    "    Returns function to switch batch norms. For use with nn.Sequential.\n",
    "    '''\n",
    "    def _idx_switcher(module):\n",
    "        if type(module) is MultiBatchNorm:\n",
    "            assert 0 <= idx <= module.n_aux_bn, \\\n",
    "            'Index {0} out of range. Expected between 0 and {1}'.format(idx, module.n_aux_bn)\n",
    "            module.bn_idx = idx\n",
    "    return _idx_switcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU_Block(nn.Module):\n",
    "    '''\n",
    "    Creates a RELU block.\n",
    "    '''\n",
    "    def __init__(self, in_features, out_features, dropout=True, dropout_prob=.1, batch_norm=True, bias=True):\n",
    "        super(ReLU_Block, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features, bias)\n",
    "        \n",
    "        if batch_norm:\n",
    "            self.batch_norm = nn.BatchNorm1d(out_features)\n",
    "        else:\n",
    "            self.register_parameter('batch_norm', None)\n",
    "            \n",
    "        if dropout:\n",
    "            self.dropout = nn.Dropout(dropout_prob)\n",
    "        else:\n",
    "            self.register_parameter('dropout', None)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        if self.dropout is not None:\n",
    "            input = self.dropout(input)\n",
    "        x = self.linear(input)\n",
    "        if self.batch_norm is not None:\n",
    "            x = self.batch_norm(x)\n",
    "\n",
    "        return nn.functional.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier(nn.Module):\n",
    "    def __init__(self, image_size, classes, depth, block_type, block_kws={}, name='default'):\n",
    "        super(classifier, self).__init__()\n",
    "        self.classes = classes\n",
    "        if block_type == 'serlu':\n",
    "            block = SERLU_Block\n",
    "        elif block_type == 'selu':\n",
    "            block = SELU_Block\n",
    "        else:\n",
    "            block = ReLU_Block\n",
    "            \n",
    "        layer_sizes = linspace(image_size, classes, depth, dtype=int)\n",
    "        in_sizes, out_sizes = layer_sizes[:-1], layer_sizes[1:]\n",
    "        \n",
    "        net = [nn.Flatten()]\n",
    "        assert depth >= 1, 'Depth must be at least 1. Recieved {0}'.format(depth)\n",
    "        for in_size, out_size in zip(in_sizes[:-1], out_sizes[:-1]):\n",
    "            net.append(block(in_size, out_size, **block_kws))\n",
    "            \n",
    "        if 'bias' in block_kws:\n",
    "            bias = block_kws['bias']\n",
    "        else:\n",
    "            bias = True\n",
    "        net.append(nn.Linear(in_sizes[-1], out_sizes[-1], bias))\n",
    "        self.net = nn.Sequential(*net)\n",
    "        \n",
    "        self.name = name\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.net(input)\n",
    "    \n",
    "    def classify(self, input):\n",
    "        _, classes = t.max(self.net(input), 1)\n",
    "        return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(classifier, optimizer, epochs, device, verbose=True):\n",
    "    history = []\n",
    "    cum_time = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        classifier.train()\n",
    "        for batch_nb, batch in enumerate(training_loader):\n",
    "            images, labels = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "            start = time()\n",
    "            #Assign nats\n",
    "            x = classifier(images)\n",
    "\n",
    "            #Compute loss\n",
    "            loss = nn.functional.cross_entropy(x, labels)\n",
    "            \n",
    "            #Update network\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            cum_time += time()-start\n",
    "\n",
    "        #Validate after training\n",
    "        score = test_classifier(classifier, device)\n",
    "        if verbose:\n",
    "            print_progress({'epoch': epoch}, {'Portion correct': score})\n",
    "        history.append(score)\n",
    "    return history, cum_time\n",
    "\n",
    "def test_classifier(classifier, device):\n",
    "    correct = 0\n",
    "    nb_samples = len(testing_set)\n",
    "    with t.no_grad():\n",
    "        classifier.eval()\n",
    "        for batch in testing_loader:\n",
    "            images, labels = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "            #Assign classes\n",
    "            assigned = classifier.classify(images)\n",
    "\n",
    "            #Compute correct assigned\n",
    "            correct += float(t.sum(assigned==labels))\n",
    "\n",
    "    return correct/nb_samples\n",
    "\n",
    "def attack_classifier(classifier, device):\n",
    "    correct = 0\n",
    "    nb_samples = len(testing_set)\n",
    "    with t.no_grad():\n",
    "        classifier.eval()\n",
    "        for batch in testing_loader:\n",
    "            images, labels = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "            #Assign classes\n",
    "            assigned = classifier.classify(images)\n",
    "\n",
    "            #Compute correct assigned\n",
    "            correct += float(t.sum(assigned==labels))\n",
    "\n",
    "    return correct/nb_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose training device (cpu vs gpu/cuda) based on availability\n",
    "device = 'cuda' if t.cuda.is_available() else 'cpu'\n",
    "\n",
    "out_size = 10\n",
    "epochs = 15\n",
    "depths = [4, 8, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train relu-4: 0 m 58.8 s.\n",
      "Final validation accuracy: 57.6%\n",
      "Time to train relu-8: 2 m 19.2 s.\n",
      "Final validation accuracy: 57.8%\n",
      "Time to train relu-12: 3 m 38.3 s.\n",
      "Final validation accuracy: 57.4%\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "relu_history = []\n",
    "for depth in depths:\n",
    "    name = 'relu-{0}'.format(depth)\n",
    "    ReLU_net = classifier(image_size, out_size, depth, 'relu', name=name)\n",
    "    ReLU_optim = t.optim.Adam(ReLU_net.parameters(), lr=lr)\n",
    "    ReLU_net.to(device)\n",
    "    history, cum_time = train_classifier(ReLU_net, ReLU_optim, epochs, device, verbose=False)\n",
    "    relu_history.append(history)\n",
    "    print('Time to train {0}: {1:.0f} m {2:.1f} s.'.format(name, cum_time//60, cum_time%60))\n",
    "    print('Final validation accuracy: {0:.1%}'.format(history[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train selu-4: 0 m 31.1 s.\n",
      "Time to train selu-8: 1 m 10.1 s.\n",
      "Time to train selu-12: 1 m 54.7 s.\n"
     ]
    }
   ],
   "source": [
    "selu_history = []\n",
    "\n",
    "for depth in depths:\n",
    "    name = 'selu-{0}'.format(depth)\n",
    "    SELU_net = classifier(image_size, out_size, depth, 'selu', {'bias': False}, name=name)\n",
    "    SELU_optim = t.optim.Adadelta(SELU_net.parameters())\n",
    "    SELU_net.to(device)\n",
    "    history, cum_time = train_classifier(SELU_net, SELU_optim, epochs, device, verbose=False)\n",
    "    selu_history.append(history)\n",
    "    print('Time to train {0}: {1:.0f} m {2:.1f} s.'.format(name, cum_time//60, cum_time%60))\n",
    "    print('Final validation accuracy: {0:.1%}'.format(history[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SERLU_net = classifier(image_size, out_size, depth, h_size, 'serlu')\n",
    "# #Move networks to selected device\n",
    "# SERLU_net.to(device)\n",
    "\n",
    "# #Set up optimizer\n",
    "# SERLU_optim = t.optim.Adamax(SERLU_net.parameters(), lr=0.0005)\n",
    "\n",
    "# #Train\n",
    "# train_classifier(SERLU_net, SERLU_optim, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adversary(classifier, image, desired_label, iterations, scale=1., lr=5e-2):\n",
    "    classifier.eval()\n",
    "    noise = t.zeros_like(image, requires_grad=True)\n",
    "    optim = t.optim.SGD([noise], lr=lr)\n",
    "    for _ in range(iterations):\n",
    "        optim.zero_grad()\n",
    "        new_image = (image+noise)/t.max(image+noise)\n",
    "        loss = nn.functional.cross_entropy(classifier(new_image), desired_label)+scale*noise.norm()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGSA(image, grad_data, eps):\n",
    "    noise = grad_data.sign()\n",
    "    new_image = t.clamp(image+eps*noise, 0, 1)\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.to(device)\n",
    "image.requires_grad = True\n",
    "predictions = SELU_net(image)\n",
    "loss = nn.functional.cross_entropy(predictions, t.tensor(label).view(1).to(device))\n",
    "ReLU_net.zero_grad()\n",
    "loss.backward()\n",
    "new_image = FGSA(image, image.grad.data, .05)\n",
    "print(nn.functional.softmax(ReLU_net(new_image), dim=1).tolist())\n",
    "print(label)\n",
    "plt.imshow(to_pil_image(new_image.squeeze().cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def before_and_after(classifier, old_image, old_label, new_image, new_label, class_names):\n",
    "    old_p = nn.functional.softmax(ReLU_net(image), 1).flatten().tolist()\n",
    "    new_p = nn.functional.softmax(ReLU_net(new_image), 1).flatten().tolist()\n",
    "    def _generate_text(label, p):\n",
    "        return '{0}: {1:.6f}'.format(class_names[label], p[label])\n",
    "    old_label = int(old_label)\n",
    "    new_label = int(new_label)\n",
    "    text = ['Before']\n",
    "    text += [_generate_text(old_label, old_p)]\n",
    "    text += [_generate_text(new_label, old_p)]\n",
    "    text += ['After']\n",
    "    text += [_generate_text(old_label, new_p)]\n",
    "    text += [_generate_text(new_label, new_p)]\n",
    "    print(*text, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = training_set[1]\n",
    "plt.imshow(to_pil_image(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.to(device)\n",
    "image = image.reshape((1, *image_shape))\n",
    "new_label = t.tensor(1, device=device).view(1)\n",
    "new_image = create_adversary(ReLU_net, image, new_label, 100, scale=1)\n",
    "\n",
    "p_old = nn.functional.softmax(ReLU_net(image), 1).flatten().tolist()\n",
    "p_new = nn.functional.softmax(ReLU_net(new_image), 1).flatten().tolist()\n",
    "before_and_after(ReLU_net, image, label, new_image, new_label, training_set.classes)\n",
    "\n",
    "new_image = new_image.squeeze()\n",
    "plt.imshow(to_pil_image(new_image.cpu()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_images = training_set.data/255.\n",
    "channel_1 = raw_images[:, :, :, 0]\n",
    "channel_2 = raw_images[:, :, :, 1]\n",
    "channel_3 = raw_images[:, :, :, 2]\n",
    "\n",
    "print([channel_1.mean(), channel_2.mean(), channel_3.mean()])\n",
    "print([channel_1.std(), channel_2.std(), channel_3.std()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(30, 30), nn.BatchNorm1d(30), nn.Linear(30, 1), nn.Sigmoid())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_net = []\n",
    "for module in net.children():\n",
    "    if type(module) == nn.BatchNorm1d:\n",
    "        new_net.append(MultiBatchNorm(module))\n",
    "    else:\n",
    "        new_net.append(module)\n",
    "        \n",
    "new_net = nn.Sequential(*new_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.3339e-03,  1.9097e-03, -6.0139e-06, -1.2178e-03,  3.2229e-03,\n",
      "        -9.0382e-04,  3.3276e-03, -3.8931e-04,  1.5262e-03,  8.2239e-04,\n",
      "         2.3829e-03, -3.2390e-05,  2.8183e-04, -8.9168e-04,  1.8541e-03,\n",
      "         2.5105e-03, -1.8209e-03,  4.2325e-04, -1.7255e-05, -1.9175e-05,\n",
      "         4.0801e-03,  3.5153e-03,  3.6646e-03,  1.3210e-03, -1.9340e-04,\n",
      "        -9.8893e-06,  3.3115e-03,  9.8219e-04,  4.9654e-03, -7.9064e-05])\n",
      "tensor([-1.2743e-03,  3.1779e-04, -1.5712e-05,  5.7013e-04,  6.6245e-03,\n",
      "        -4.6573e-04,  4.1493e-03, -2.6825e-04,  3.0782e-03, -8.0361e-04,\n",
      "         2.6034e-03,  7.3976e-04, -4.7824e-05, -1.1523e-03,  2.6266e-03,\n",
      "         5.1047e-03, -1.0694e-03,  4.5707e-04, -6.4052e-05, -2.2515e-05,\n",
      "         3.4765e-03,  2.0829e-03,  3.9389e-03,  3.8660e-03,  4.8316e-04,\n",
      "         6.2607e-05,  2.4714e-03,  1.1119e-03,  4.3492e-03,  2.1327e-04])\n"
     ]
    }
   ],
   "source": [
    "new_net.zero_grad()\n",
    "new_net.apply(switch_bn(0))\n",
    "r = t.rand((30, 30))\n",
    "y = (r.mean(1, keepdim=True)-new_net(r)).pow(2).mean()\n",
    "y.backward()\n",
    "print(new_net[1].main_bn.weight.grad)\n",
    "print(new_net[1].aux_bn[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.])\n",
      "tensor([ 7.4158e-04,  1.1048e-03, -1.9102e-05,  1.2424e-03,  1.0603e-02,\n",
      "        -4.4003e-03,  8.0027e-03, -7.2566e-04,  7.7528e-03, -3.4236e-04,\n",
      "         7.4775e-03,  1.4361e-03,  8.6736e-04, -1.0763e-03,  5.9851e-03,\n",
      "         8.2362e-03, -1.5673e-03,  7.5439e-04, -9.3011e-07, -3.7179e-05,\n",
      "         8.4422e-03,  2.6506e-03,  6.6694e-03,  6.2466e-03,  1.0359e-04,\n",
      "         5.6810e-04,  7.1359e-03,  1.9257e-03,  2.7720e-03, -3.9740e-04])\n"
     ]
    }
   ],
   "source": [
    "new_net.zero_grad()\n",
    "new_net.apply(switch_bn(1))\n",
    "r = t.rand((30, 30))\n",
    "y = (r.mean(1, keepdim=True)-new_net(r)).pow(2).mean()\n",
    "y.backward()\n",
    "print(new_net[1].main_bn.weight.grad)\n",
    "print(new_net[1].aux_bn[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for parameters in new_net[1].parameters():\n",
    "    print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
